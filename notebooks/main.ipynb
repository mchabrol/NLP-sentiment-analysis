{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as the main entry point to train, evaluate, and compare the performance of different NLP models implemented in separate Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "base_path = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Base model : TF-IDF and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.tf_idf import TfidfClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.path.join(base_path, \"aclImdb\")\n",
    "df_train = pd.read_csv(os.path.join(datasets_path, \"df_train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(datasets_path, \"df_test.csv\"))\n",
    "\n",
    "X = df_train['comment']\n",
    "y = df_train['sentiment']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 5000,\n",
       " 'use_idf': True,\n",
       " 'alpha': 1.0,\n",
       " 'train_accuracy': 0.86855,\n",
       " 'val_accuracy': 0.8498}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_classifier = TfidfClassifier(X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val, \n",
    "                                   train_file_path=os.path.join(datasets_path, \"df_train.csv\"), test_file_path=os.path.join(datasets_path, \"df_test.csv\"))\n",
    "\n",
    "tfidf_classifier.run_experiments(\n",
    "    max_features_list=[1000, 2000, 5000],\n",
    "    use_idf_list=[True, False],\n",
    "    alpha_list=[0.1, 1.0, 10.0]\n",
    ")\n",
    "\n",
    "tfidf_classifier.get_best_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Accuracy on train set for TF-IDF & Naive Bayes ========\n",
      " 0.865\n",
      "======== Accuracy on test set for TF-IDF & Naive Bayes ========\n",
      " 0.84056\n"
     ]
    }
   ],
   "source": [
    "#Evaluate perf on test set\n",
    "train_accuracy, test_accuracy = tfidf_classifier.evaluate_on_test(config = tfidf_classifier.best_config)\n",
    "\n",
    "print(\"======== Accuracy on train set for TF-IDF & Naive Bayes ========\\n\", train_accuracy)\n",
    "print(\"======== Accuracy on test set for TF-IDF & Naive Bayes ========\\n\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Word2vec and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.word2vec import ReviewTokenizer, Word2VecEmbedder, SentimentClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Accuracy on val set for Word2vec and SVC ========\n",
      " 0.865\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(datasets_path, \"df_train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(datasets_path, \"df_test.csv\"))\n",
    "\n",
    "# tokenisation\n",
    "tokenized_reviews_train = [ReviewTokenizer.tokenize(text) for text in df_train['comment']]\n",
    "\n",
    "# # train embeddings\n",
    "embedder = Word2VecEmbedder()\n",
    "embedder.train(tokenized_reviews_train)\n",
    "X_embeddings = embedder.embed_reviews(tokenized_reviews_train)\n",
    "embedder.save_embeddings(X_embeddings, os.path.join(base_path, 'aclImdb/embeddings/X_train_word2vec_embeddings.pkl'))\n",
    "\n",
    "# train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_embeddings, df_train['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# train and evaluate classifier\n",
    "clf = SentimentClassifier(classifier=LinearSVC())\n",
    "clf.train(X_train, y_train)\n",
    "clf.evaluate(X_val, y_val)\n",
    "print(\"======== Accuracy on val set for Word2vec and SVC ========\\n\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Accuracy on train set for Word2vec and SVC ========\n",
      " 0.87965\n",
      "======== Accuracy on test set for Word2vec and SVC ========\n",
      " 0.86836\n"
     ]
    }
   ],
   "source": [
    "#Check performance on test set \n",
    "clf.train(X_embeddings, df_train['sentiment'])\n",
    "\n",
    "tokenized_reviews_test = [ReviewTokenizer.tokenize(text) for text in df_test['comment']]\n",
    "\n",
    "X_test_embeddings = embedder.embed_reviews(tokenized_reviews_test)\n",
    "test_accuracy, test_report = clf.evaluate(X_test_embeddings, df_test['sentiment'])\n",
    "train_accuracy, train_report = clf.evaluate(X_train, y_train)\n",
    "\n",
    "print(\"======== Accuracy on train set for Word2vec and SVC ========\\n\", train_accuracy)\n",
    "print(\"======== Accuracy on test set for Word2vec and SVC ========\\n\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III- RoBERTa\n",
    "For more info on training have a look at `roberta_training.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1HcY9WA-ded5y5YLDNtGwH9cnO0F6aFjo\n",
      "From (redirected): https://drive.google.com/uc?id=1HcY9WA-ded5y5YLDNtGwH9cnO0F6aFjo&confirm=t&uuid=4286792a-9f88-4a43-9fe7-3ced26ff56c4\n",
      "To: /Users/suzie/NLP-sentiment-analysis/notebooks/roberta_imbd_model.pt\n",
      "100%|██████████| 499M/499M [00:43<00:00, 11.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'roberta_imbd_model.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://drive.google.com/file/d/1HcY9WA-ded5y5YLDNtGwH9cnO0F6aFjo/view?usp=sharing' #because model size too large\n",
    "gdown.download(url, 'roberta_imbd_model.pt', fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:24<00:00, 1005.49 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:24<00:00, 1027.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating on Validation: 100%|██████████| 3125/3125 [15:03<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Validation: 100%|██████████| 3125/3125 [15:39<00:00,  3.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9487\n",
      "======== Accuracy on train set for RoBERTa ========\n",
      " {'accuracy': 0.97764}\n",
      "======== Accuracy on test set for RoBERTa ========\n",
      " {'accuracy': 0.94872}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models.roberta import RobertaTokenizer_imdb, RobertaModel_imdb\n",
    "import tqdm \n",
    "dataset_manager = RobertaTokenizer_imdb(\"roberta-base\")\n",
    "df_train = pd.read_csv(os.path.join(datasets_path, \"df_train.csv\"))\n",
    "df_train = dataset_manager.prepare_dataset(df_train)\n",
    "train_loader = dataset_manager.create_dataloader(df_train)\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(datasets_path, \"df_test.csv\"))\n",
    "df_test = dataset_manager.prepare_dataset(df_test)\n",
    "test_loader = dataset_manager.create_dataloader(df_test)\n",
    "model = RobertaModel_imdb(\"roberta-base\", num_labels=2)\n",
    "model.load_model(filepath=\"roberta_imbd_model.pt\")\n",
    "\n",
    "train_accuracy = model.evaluate(train_loader)\n",
    "test_accuracy = model.evaluate(test_loader)\n",
    "\n",
    "print(\"======== Accuracy on train set for RoBERTa ========\\n\", train_accuracy)\n",
    "print(\"======== Accuracy on test set for RoBERTa ========\\n\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
