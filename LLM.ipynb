{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "# disable warnings for libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure logger\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for embedding and classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:17:30 INFO:Loading embedding vectors...\n",
      "10:17:30 INFO:Loaded vectors with shape: (89527,)\n",
      "10:17:30 INFO:Loading words...\n",
      "10:17:30 INFO:Loaded 89527 words\n",
      "10:17:30 INFO:Verification complete - sizes match!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information:\n",
      "Number of words (vocab): 89527\n",
      "Number of vectors (rates): 89527\n",
      "\n",
      "First few words and their expected rates [('the', 0.0490972013402), ('and', 0.201363575849), ('a', 0.0333946807184), ('of', 0.099837669572), ('to', -0.0790210365788)]\n"
     ]
    }
   ],
   "source": [
    "#Expected rate for each word in the vocabulary\n",
    "\n",
    "def load_embeddings():\n",
    "    # Load rates\n",
    "    logger.info(\"Loading embedding vectors...\")\n",
    "    rates= np.genfromtxt('aclImdb/imdbEr.txt')\n",
    "    logger.info(f\"Loaded vectors with shape: {rates.shape}\")\n",
    "    \n",
    "    # Load associated words\n",
    "    logger.info(\"Loading words...\")\n",
    "    with open('aclImdb/imdb.vocab', 'r', encoding='utf-8') as f:\n",
    "        words = [line.strip() for line in f.readlines()]\n",
    "    logger.info(f\"Loaded {len(words)} words\")\n",
    "    \n",
    "    if len(words) != rates.shape[0]:\n",
    "        raise ValueError(f\"Mismatch between number of words ({len(words)}) and vectors ({rates.shape[0]})\")\n",
    "    \n",
    "    logger.info(\"Verification complete - sizes match!\")\n",
    "    \n",
    "    return rates, words\n",
    "\n",
    "rates, words = load_embeddings()\n",
    "\n",
    "print(\"\\nDataset information:\")\n",
    "print(f\"Number of words (vocab): {len(words)}\")\n",
    "print(f\"Number of vectors (rates): {rates.shape[0]}\")\n",
    "print(f\"\\nFirst few words and their expected rates {[(word, rate) for (word, rate) in zip(words[:5], rates[:5])]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('aclImdb/df_train')\n",
    "X = df_train['comment']\n",
    "y = df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() \n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.57s/it]\n"
     ]
    }
   ],
   "source": [
    "def generate_bert_embeddings(reviews, batch_size=32):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(reviews), batch_size)):\n",
    "        batch = reviews[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # embeddings du token [CLS] (premier token)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.append(cls_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "#generate embeddings\n",
    "reviews = X.astype(str).tolist()\n",
    "embeddings = generate_bert_embeddings(reviews, batch_size=32)\n",
    "\n",
    "np.save('aclImdb/embeddings/X_train_embeddings.npy', embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensions :(10, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('aclImdb/embeddings/X_train_embeddings.npy')\n",
    "print(f\"Embedding dimensions :{X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y[:10], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Évaluation\n",
    "print(f'Accuracy : {accuracy_score(y_val, y_pred):.4f}')\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SVM linéaire): 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "print(f'Accuracy (SVM linéaire): {accuracy_score(y_val, y_pred_svm):.4f}')\n",
    "print(classification_report(y_val, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO : word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
